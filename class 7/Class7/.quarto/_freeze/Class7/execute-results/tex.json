{
  "hash": "7d5bb5dcbb474047754eda1f2559f5de",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Class 7: Machine Learning 1\"\nauthor: \"Michael Romero (A18135877)\"\nformat: pdf\n---\n\nToday we will explore some fundamental machine learning methods including clustering and dimensionality reduction.\n\n## K-means clustering\n\nTo see how this works let's first makeup some data to cluster where we know what the answer should be. We can use the `rnorm()` function to help here:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhist( rnorm(500, mean=5))\n```\n\n::: {.cell-output-display}\n![](Class7_files/figure-pdf/unnamed-chunk-1-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx<- c(rnorm(30, mean=-3),rnorm(30, mean=3))\ny<- rev(x)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx<- cbind(x,y)\nplot(x)\n```\n\n::: {.cell-output-display}\n![](Class7_files/figure-pdf/unnamed-chunk-3-1.pdf){fig-pos='H'}\n:::\n:::\n\n\nThe function for K-means clustering in \"base\" R is `kmeans()` \n\n\n::: {.cell}\n\n```{.r .cell-code}\nk<-kmeans(x,centers=2)\nk\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nK-means clustering with 2 clusters of sizes 30, 30\n\nCluster means:\n          x         y\n1  3.095520 -2.877648\n2 -2.877648  3.095520\n\nClustering vector:\n [1] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1\n[39] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n\nWithin cluster sum of squares by cluster:\n[1] 49.72438 49.72438\n (between_SS / total_SS =  91.5 %)\n\nAvailable components:\n\n[1] \"cluster\"      \"centers\"      \"totss\"        \"withinss\"     \"tot.withinss\"\n[6] \"betweenss\"    \"size\"         \"iter\"         \"ifault\"      \n```\n\n\n:::\n:::\n\n\nTo get ath the results fo the returned list object we can use the dollar `$` syntax\n\n>Q. How many points are in each cluster? 30\n\n\n::: {.cell}\n\n```{.r .cell-code}\nk$size\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 30 30\n```\n\n\n:::\n:::\n\n\n>Q. What 'component' of your result object details \n      - cluster assignment/membership?\n      - cluster center?\n      \n\n::: {.cell}\n\n```{.r .cell-code}\nk$cluster\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1\n[39] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n```\n\n\n:::\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nk$centers\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          x         y\n1  3.095520 -2.877648\n2 -2.877648  3.095520\n```\n\n\n:::\n:::\n\n\n>Q. Make a clustering results figure of the data colored by cluster membership. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(x, col=k$cluster, pch=16)\npoints(k$centers, col=\"blue\", pch=15, cex=2)\n```\n\n::: {.cell-output-display}\n![](Class7_files/figure-pdf/unnamed-chunk-8-1.pdf){fig-pos='H'}\n:::\n:::\n\n\nK-means clustering is very popular as it is very fast and relatively straight forward: it takes numeric data as input and returns the clusterm membership vector etc.\n\nThe \"issue\" is we tell `kmeans()` how many clusters we want!\n\n> Q. Run kmeans again and cluster into 4 groups/clusters and plot the results like we did above. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nk4<-kmeans(x, centers = 4)\nplot(x, col=k4$cluster)\npoints(k4$centers, pch=15)\n```\n\n::: {.cell-output-display}\n![](Class7_files/figure-pdf/unnamed-chunk-9-1.pdf){fig-pos='H'}\n:::\n:::\n\n\nScree plot to pick k `centers` value\n\nbrute-force\n\n\n::: {.cell}\n\n```{.r .cell-code}\nk1<-kmeans(x, centers=1)\nk2<-kmeans(x, centers=2)\nk3<-kmeans(x, centers=3)\nk4<-kmeans(x, centers=4)\nk5<-kmeans(x, centers=5)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nz<-c(k1$tot.withinss,\n  k2$tot.withinss,\n  k3$tot.withinss,\n  k4$tot.withinss,\n  k5$tot.withinss)\n\nplot(z, typ=\"b\")\n```\n\n::: {.cell-output-display}\n![](Class7_files/figure-pdf/unnamed-chunk-11-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn<-NULL\nfor(i in 1:5){\n  n<- c(n, kmeans(x, centers=i)$tot.withinss)\n}\n\nplot(n, typ=\"b\")\n```\n\n::: {.cell-output-display}\n![](Class7_files/figure-pdf/unnamed-chunk-12-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\nElbow point is the region after the \"scree\" \"cliff-fall\" so in this case it is at cluster=2.\n\n##Hierarchical Clustering\n\nThe main \"base\" R function for Hierarchical Clustering is called `hclust()`. Here we can't just input our data we need to first calculate a distance matrix (e.g. `dist()`) for our data and use this as input to `hclust()`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd<-dist(x)\nhc<-hclust(d)\nhc\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nhclust(d = d)\n\nCluster method   : complete \nDistance         : euclidean \nNumber of objects: 60 \n```\n\n\n:::\n:::\n\n\nThere is a plot method for hclust results lets try it\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(hc)\nabline(h=8, col=\"red\")\n```\n\n::: {.cell-output-display}\n![](Class7_files/figure-pdf/unnamed-chunk-14-1.pdf){fig-pos='H'}\n:::\n\n```{.r .cell-code}\ncutree(hc, h=8)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2\n[39] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n```\n\n\n:::\n:::\n\nTo get our cluster \"membership\" vector (i.e. our main clustering result) we can \"cut\" the tree at a given height or at a height that yields a given \"k\" groups.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncutree(hc,h=8)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2\n[39] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngrps<-cutree(hc, k=2)\n```\n:::\n\n\n> Q. Plot the data with our hclust result coloring\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(x, col=grps)\n```\n\n::: {.cell-output-display}\n![](Class7_files/figure-pdf/unnamed-chunk-17-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n# Principal Component Analysis (PCA)\n\n## PCA of UK food data\n\nImport food data from an online CSV file:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nurl<- \"https://tinyurl.com/UK-foods\"\nx<- read.csv(url)\nhead(x)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n               X England Wales Scotland N.Ireland\n1         Cheese     105   103      103        66\n2  Carcass_meat      245   227      242       267\n3    Other_meat      685   803      750       586\n4           Fish     147   160      122        93\n5 Fats_and_oils      193   235      184       209\n6         Sugars     156   175      147       139\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrownames(x) <- x[,1]\nx<-x[,-1]\nx\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                    England Wales Scotland N.Ireland\nCheese                  105   103      103        66\nCarcass_meat            245   227      242       267\nOther_meat              685   803      750       586\nFish                    147   160      122        93\nFats_and_oils           193   235      184       209\nSugars                  156   175      147       139\nFresh_potatoes          720   874      566      1033\nFresh_Veg               253   265      171       143\nOther_Veg               488   570      418       355\nProcessed_potatoes      198   203      220       187\nProcessed_Veg           360   365      337       334\nFresh_fruit            1102  1137      957       674\nCereals                1472  1582     1462      1494\nBeverages                57    73       53        47\nSoft_drinks            1374  1256     1572      1506\nAlcoholic_drinks        375   475      458       135\nConfectionery            54    64       62        41\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx<-read.csv(url, row.names=1)\nx\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                    England Wales Scotland N.Ireland\nCheese                  105   103      103        66\nCarcass_meat            245   227      242       267\nOther_meat              685   803      750       586\nFish                    147   160      122        93\nFats_and_oils           193   235      184       209\nSugars                  156   175      147       139\nFresh_potatoes          720   874      566      1033\nFresh_Veg               253   265      171       143\nOther_Veg               488   570      418       355\nProcessed_potatoes      198   203      220       187\nProcessed_Veg           360   365      337       334\nFresh_fruit            1102  1137      957       674\nCereals                1472  1582     1462      1494\nBeverages                57    73       53        47\nSoft_drinks            1374  1256     1572      1506\nAlcoholic_drinks        375   475      458       135\nConfectionery            54    64       62        41\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbarplot(as.matrix(x), beside=T, col=rainbow(nrow(x)))\n```\n\n::: {.cell-output-display}\n![](Class7_files/figure-pdf/unnamed-chunk-21-1.pdf){fig-pos='H'}\n:::\n:::\n\n\nThere is one plot that can be useful for small datasets:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npairs(x, col=rainbow(nrow(x)), pch=16)\n```\n\n::: {.cell-output-display}\n![](Class7_files/figure-pdf/unnamed-chunk-22-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n> Main point: It can be difficult to spot major trends and patterns even in relatively small multivariate datasets (here we only have 17 dimensions, typically we have 1000s).\n\n\n## PCA to the rescue\n\nThe main function in \"base\" R for PCA is called `prcomp()` \nI will take the transpose of our data so the \"foods\" are in the columns:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npca<-prcomp( t(x) )\nsummary(pca)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nImportance of components:\n                            PC1      PC2      PC3       PC4\nStandard deviation     324.1502 212.7478 73.87622 2.921e-14\nProportion of Variance   0.6744   0.2905  0.03503 0.000e+00\nCumulative Proportion    0.6744   0.9650  1.00000 1.000e+00\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncols<- c(\"orange\", \"red\", \"blue\", \"darkgreen\")\nplot(pca$x[,1], pca$x[,2], col=cols, pch =16)\n```\n\n::: {.cell-output-display}\n![](Class7_files/figure-pdf/unnamed-chunk-24-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(pca$x) +\n  aes(PC1, PC2) +\n  geom_point(col=cols)\n```\n\n::: {.cell-output-display}\n![](Class7_files/figure-pdf/unnamed-chunk-26-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(pca$rotation) +\n  aes(PC1, rownames(pca$rotation)) +\n  geom_col()\n```\n\n::: {.cell-output-display}\n![](Class7_files/figure-pdf/unnamed-chunk-27-1.pdf){fig-pos='H'}\n:::\n:::\n\n\nPCA looks super useful and we will come back to describe this further next day :-)\n\n\n",
    "supporting": [
      "Class7_files/figure-pdf"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}